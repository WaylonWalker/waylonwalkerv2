{"componentChunkName":"component---src-templates-blog-post-js","path":"/find-replace/","result":{"data":{"markdownRemark":{"id":"d94c3f80-1c8e-57f9-8193-26c6272e315f","html":"<h2>grepr</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function-name function\">grepr</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>grep -iRl <span class=\"token string\">\"<span class=\"token variable\">$1</span>\"</span> <span class=\"token operator\">|</span> <span class=\"token function\">xargs</span> <span class=\"token function\">sed</span> -i <span class=\"token string\">\"s/<span class=\"token variable\">$1</span>/<span class=\"token variable\">$2</span>/g\"</span><span class=\"token punctuation\">}</span>\n\n```bash\n<span class=\"token function-name function\">grepr</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>grep -iRl <span class=\"token string\">\"<span class=\"token variable\">$1</span>\"</span> <span class=\"token operator\">|</span> <span class=\"token function\">xargs</span> <span class=\"token function\">sed</span> -i <span class=\"token string\">\"s/<span class=\"token variable\">$1</span>/<span class=\"token variable\">$2</span>/g\"</span><span class=\"token punctuation\">}</span></code></pre></div>\n<h2>grepd</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">grepd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>grep <span class=\"token operator\">-</span>iRl <span class=\"token string\">\"$1\"</span> <span class=\"token operator\">|</span> xargs sed <span class=\"token operator\">-</span>i <span class=\"token string\">\"/^$1/d\"</span><span class=\"token punctuation\">}</span></code></pre></div>\n<h2>CocSearch</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">:CocSearch status: <span class=\"token string\">'false'</span> -g *.md</code></pre></div>","fields":{"slug":"/find-replace/"},"frontmatter":{"date":"2020-11-12T05:00:00.000Z","title":"Find and Replace in the Terminal.","description":"notes about find and replace techniques","status":"published","cover":{"absolutePath":"/home/runner/work/waylonwalkerv2/waylonwalkerv2/static/find-replace-xmas2020.png","xsm_img":{"fixed":{"src":"/static/bea20c9acb4e061e353f5a6e73bf096b/ef958/find-replace-xmas2020.png","srcWebp":"/static/bea20c9acb4e061e353f5a6e73bf096b/f6b6d/find-replace-xmas2020.webp"}},"sm_img":{"fixed":{"src":"/static/bea20c9acb4e061e353f5a6e73bf096b/630fb/find-replace-xmas2020.png","srcWebp":"/static/bea20c9acb4e061e353f5a6e73bf096b/403a4/find-replace-xmas2020.webp"}},"med_img":{"fixed":{"src":"/static/bea20c9acb4e061e353f5a6e73bf096b/46604/find-replace-xmas2020.png","srcWebp":"/static/bea20c9acb4e061e353f5a6e73bf096b/e9589/find-replace-xmas2020.webp"}},"full":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABjElEQVQY032RyU7jQBCGfedGlATHCXZsE9u9VbeduL2RGAg7gwQSImI5wExAk5FAArFdEBIceALeZN5vmuUwJ6RPpapS/VLVX1rTFYqGGzYdbrhc5YbqOKArbDDnIh/njJXABgAFFQWHlIkMRAIi1hqu0B0+Y8NHInRX1Nsw4/C6UnZihMumG2E2CHBBaMGUnueUZ4QnjMeaUjbnQhvLusVqFq1ZrOV1qyapzGLd4u2ONBzh+VlWbIbRQoAkIpKwhH6JbTCC+OTibu9wvHd0dnAyUZxf3F7ePK5sj8r13Z3R6a/x1f5oPJnc/J5c3z88HRz99HEEodSmbU5baMhTN+yjaBCEfY8XPF2GZNiBwiGJTRKZb4hwMc3W8vm1wcJmmg8JSCakZvn87+vzy/GfKSOomaT6QaWFKi1cNdUVVJWGLQjrY5IjkiAsEZUg0ve1GcDb3eFW9mN6lnya9z/KyM9odroCyiRaKnur/d6wiBYdv6tV20y3sN6mauIb1AsaDre9nhvElhepR6rOP2TCXfYirbfhAAAAAElFTkSuQmCC","width":1000,"height":420,"src":"/static/bea20c9acb4e061e353f5a6e73bf096b/a8734/find-replace-xmas2020.png","srcSet":"/static/bea20c9acb4e061e353f5a6e73bf096b/a8734/find-replace-xmas2020.png 1x"},"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABjElEQVQY032RyU7jQBCGfedGlATHCXZsE9u9VbeduL2RGAg7gwQSImI5wExAk5FAArFdEBIceALeZN5vmuUwJ6RPpapS/VLVX1rTFYqGGzYdbrhc5YbqOKArbDDnIh/njJXABgAFFQWHlIkMRAIi1hqu0B0+Y8NHInRX1Nsw4/C6UnZihMumG2E2CHBBaMGUnueUZ4QnjMeaUjbnQhvLusVqFq1ZrOV1qyapzGLd4u2ONBzh+VlWbIbRQoAkIpKwhH6JbTCC+OTibu9wvHd0dnAyUZxf3F7ePK5sj8r13Z3R6a/x1f5oPJnc/J5c3z88HRz99HEEodSmbU5baMhTN+yjaBCEfY8XPF2GZNiBwiGJTRKZb4hwMc3W8vm1wcJmmg8JSCakZvn87+vzy/GfKSOomaT6QaWFKi1cNdUVVJWGLQjrY5IjkiAsEZUg0ve1GcDb3eFW9mN6lnya9z/KyM9odroCyiRaKnur/d6wiBYdv6tV20y3sN6mauIb1AsaDre9nhvElhepR6rOP2TCXfYirbfhAAAAAElFTkSuQmCC","aspectRatio":2.380952380952381,"src":"/static/bea20c9acb4e061e353f5a6e73bf096b/a8734/find-replace-xmas2020.png","srcSet":"/static/bea20c9acb4e061e353f5a6e73bf096b/2d6f8/find-replace-xmas2020.png 250w,\n/static/bea20c9acb4e061e353f5a6e73bf096b/03ac3/find-replace-xmas2020.png 500w,\n/static/bea20c9acb4e061e353f5a6e73bf096b/a8734/find-replace-xmas2020.png 1000w","sizes":"(max-width: 1000px) 100vw, 1000px"}}}}}},"pageContext":{"id":"d94c3f80-1c8e-57f9-8193-26c6272e315f","prev":{"id":"38f2923e-cc60-5251-8716-2278fd276ee8","html":"<p><code class=\"language-text\">find-kedro</code> is a small library to enhance your kedro experience.  It looks through your modules to find kedro pipelines, nodes, and iterables (lists, sets, tuples) of nodes.  It then assembles them into a dictionary of pipelines, each module will create a separate pipeline, and <code class=\"language-text\">__default__</code> being a combination of all pipelines.  This format is compatible with the kedro <code class=\"language-text\">_create_pipelines</code> format.</p>\n<p><img src=\"https://github.com/WaylonWalker/find-kedro/workflows/Python%20package/badge.svg\" alt=\"Python package\"></p>\n<p><img src=\"https://github.com/WaylonWalker/find-kedro/workflows/Test/badge.svg\" alt=\"Test\"></p>\n<p><a href=\"https://find-kedro.waylonwalker.com\"><img src=\"https://github.com/WaylonWalker/find-kedro/workflows/Build-Docs/badge.svg?branch=master\" alt=\"Build-Docs\"></a></p>\n<h2><img src=\"https://waylonwalker.com/find-kedro-release-1.png\" alt=\"Motivation\"></h2>\n<p><code class=\"language-text\">kedro</code> is a ‚ú® fantastic project that allows for super-fast prototyping of data pipelines, while yielding production-ready pipelines. <code class=\"language-text\">find-kedro</code> enhances this experience by adding a pytest like node/pipeline discovery eliminating the need to bubble up pipelines through modules.</p>\n<p>When working on larger pipeline projects, it is advisable to break your project down into different sub-modules which requires knowledge of building python libraries, and knowing how to import each module correctly.  While this is not too difficult, in some cases, it can trip up even the most senior engineers, losing precious feature development time to debugging a library.</p>\n<h2><img src=\"https://waylonwalker.com/find-kedro-release-2.png\" alt=\"Installation\"></h2>\n<p><code class=\"language-text\">find-kedro</code> is deployed to pypi and can easily be <code class=\"language-text\">pip</code> installed.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">pip <span class=\"token function\">install</span> find-kedro</code></pre></div>\n<h2><img src=\"https://waylonwalker.com/find-kedro-release-3.png\" alt=\"Python Usage\"></h2>\n<p>The recommended usage of <code class=\"language-text\">find-kedro</code> is to implement it directly into your projects <code class=\"language-text\">run.py</code> module</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>context <span class=\"token keyword\">import</span> KedroContext\n<span class=\"token keyword\">from</span> find_kedro <span class=\"token keyword\">import</span> find_kedro\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ProjectContext</span><span class=\"token punctuation\">(</span>KedroContext<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">_get_pipelines</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> Pipeline<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> find_kedro<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Creating nodes</h3>\n<p><code class=\"language-text\">find-kedro</code> will not execute any functions.  It will simply look for variables that match the <code class=\"language-text\">pattern</code> and identify if they are a <code class=\"language-text\">kedro.pipeline.Pipeline</code>, <code class=\"language-text\">kedro.pipeline.nodes.Node</code>, or a list of <code class=\"language-text\">kedro.pipeline.nodes.  Node</code>'s.  If so, it will collect them into the dictionary of pipelines.</p>\n<p>There are typically <strong>three</strong> ways that pipelines are constructed with <code class=\"language-text\">find-kedro</code>; <strong>lists</strong>, <strong>single-nodes</strong>, and <strong>pipelines</strong>.</p>\n<h4>Lists</h4>\n<p>Any pattern matched list will be flattened and collected into the pipeline.  Nodes can be created all at once in the list definition.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># my-proj/pipelinies/data_engineering/pipeline</span>\n<span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> node\n<span class=\"token keyword\">from</span> <span class=\"token punctuation\">.</span>nodes <span class=\"token keyword\">import</span> split_data\n\npipeline <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    node<span class=\"token punctuation\">(</span>\n        split_data<span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">[</span><span class=\"token string\">\"example_iris_data\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"params:example_test_data_ratio\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>\n            train_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_x\"</span><span class=\"token punctuation\">,</span>\n            train_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_y\"</span><span class=\"token punctuation\">,</span>\n            test_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_x\"</span><span class=\"token punctuation\">,</span>\n            test_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_y\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span></code></pre></div>\n<p>It is also convenient many times to keep the node definition close to the function definition.  Many times I define the list at the top of the file, then append to it as I go.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># my-proj/pipelinies/data_engineering/pipeline</span>\n<span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> node\n<span class=\"token keyword\">from</span> <span class=\"token punctuation\">.</span>nodes <span class=\"token keyword\">import</span> split_data\n\nnodes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\nnodes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>\n    node<span class=\"token punctuation\">(</span>\n        split_data<span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">[</span><span class=\"token string\">\"example_iris_data\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"params:example_test_data_ratio\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>\n            train_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_x\"</span><span class=\"token punctuation\">,</span>\n            train_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_y\"</span><span class=\"token punctuation\">,</span>\n            test_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_x\"</span><span class=\"token punctuation\">,</span>\n            test_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_y\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h4>Nodes</h4>\n<p>All pattern matched <code class=\"language-text\">kedro.pipeline.node.Node</code> objects will get collected into the pipeline.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># my-proj/pipelinies/data_engineering/pipeline</span>\n<span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> node\n<span class=\"token keyword\">from</span> <span class=\"token punctuation\">.</span>nodes <span class=\"token keyword\">import</span> split_data\n\nsplit_node <span class=\"token operator\">=</span> node<span class=\"token punctuation\">(</span>\n        split_data<span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">[</span><span class=\"token string\">\"example_iris_data\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"params:example_test_data_ratio\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>\n            train_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_x\"</span><span class=\"token punctuation\">,</span>\n            train_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_y\"</span><span class=\"token punctuation\">,</span>\n            test_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_x\"</span><span class=\"token punctuation\">,</span>\n            test_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_y\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">)</span></code></pre></div>\n<h4>Pipeline</h4>\n<p>All pattern matched <code class=\"language-text\">kedro.pipeline.Pipeline</code> objects will get collected into the pipeline.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># my-project/pipelinies/data_engineering/pipeline</span>\n<span class=\"token keyword\">from</span> kedro<span class=\"token punctuation\">.</span>pipeline <span class=\"token keyword\">import</span> node<span class=\"token punctuation\">,</span> Pipeline\n<span class=\"token keyword\">from</span> <span class=\"token punctuation\">.</span>nodes <span class=\"token keyword\">import</span> split_data\n\nsplit_node <span class=\"token operator\">=</span> Pipeline<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n        node<span class=\"token punctuation\">(</span>\n            split_data<span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">[</span><span class=\"token string\">\"example_iris_data\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"params:example_test_data_ratio\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            <span class=\"token builtin\">dict</span><span class=\"token punctuation\">(</span>\n                train_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_x\"</span><span class=\"token punctuation\">,</span>\n                train_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_train_y\"</span><span class=\"token punctuation\">,</span>\n                test_x<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_x\"</span><span class=\"token punctuation\">,</span>\n                test_y<span class=\"token operator\">=</span><span class=\"token string\">\"example_test_y\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h3>Fully Qualified imports</h3>\n<p>When using fully qualified imports <code class=\"language-text\">from my_proj.pipelines.data_science.nodes import split_data</code> instead of\nrelative imports <code class=\"language-text\">from .nodes split_data</code> you will need to make sure that your project is installed, in your current path, or you set the directory</p>\n<h3><img src=\"https://waylonwalker.com/find-kedro-release-4.png\" alt=\"CLI Usage\"></h3>\n<p>The CLI provides a handy interface to search your project for nodes</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Usage: find-kedro [OPTIONS]\n\nOptions:\n  --file-patterns TEXT       glob-style file patterns for Python node module\n                             discovery\n\n  --patterns TEXT            prefixes or glob names for Python pipeline, node,\n                             or list object discovery\n\n  -d, --directory DIRECTORY  Path to save the static site to\n  --version                  Prints version and exits\n  -v, --verbose              Prints extra information for debugging\n  --help                     Show this message and exit.</code></pre></div>\n<p>Example ran with a slightly modified default <code class=\"language-text\">kedro new</code> project.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">‚ùØ find-kedro\n<span class=\"token punctuation\">{</span>\n  <span class=\"token string\">\"__default__\"</span><span class=\"token builtin class-name\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"split_data([example_iris_data,params:example_test_data_ratio]) -> [example_test_x,example_test_y,example_train_x,example_train_y]\"</span>,\n    <span class=\"token string\">\"train_model([example_train_x,example_train_y,parameters]) -> [example_model]\"</span>,\n    <span class=\"token string\">\"predict([example_model,example_test_x]) -> [example_predictions]\"</span>,\n    <span class=\"token string\">\"report_accuracy([example_predictions,example_test_y]) -> None\"</span>\n  <span class=\"token punctuation\">]</span>,\n  <span class=\"token string\">\"src.default_kedro_159.pipelines.data_engineering.pipeline\"</span><span class=\"token builtin class-name\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"split_data([example_iris_data,params:example_test_data_ratio]) -> [example_test_x,example_test_y,example_train_x,example_train_y]\"</span>\n  <span class=\"token punctuation\">]</span>,\n  <span class=\"token string\">\"src.default_kedro_159.pipelines.data_science.pipeline\"</span><span class=\"token builtin class-name\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"train_model([example_train_x,example_train_y,parameters]) -> [example_model]\"</span>,\n    <span class=\"token string\">\"predict([example_model,example_test_x]) -> [example_predictions]\"</span>,\n    <span class=\"token string\">\"report_accuracy([example_predictions,example_test_y]) -> None\"</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<h2><img src=\"https://waylonwalker.com/find-kedro-release-5.png\" alt=\"Contributing\"></h2>\n<p><strong>You're Awesome</strong> for considering a contribution!  Contributions are welcome, please check out the <a href=\"https://github.com/WaylonWalker/find-kedro/blob/master/contributing.md\">Contributing Guide</a> for more information.  Please be a positive member of the community and embrace feedback</p>\n<h2><img src=\"https://waylonwalker.com/find-kedro-release-6.png\" alt=\"Versioning\"></h2>\n<p>We use <a href=\"https://semver.org/\">SemVer</a> for versioning. For the versions available, see the <a href=\"https://github.com/WaylonWalker/find-kedro/releases\">tags on this repository</a>.</p>\n<h2><img src=\"https://waylonwalker.com/find-kedro-release-7.png\" alt=\"Authors\"></h2>\n<p><a href=\"https://github.com/WaylonWalker\"><img src=\"https://avatars1.githubusercontent.com/u/22648375?s=120&#x26;v=4\" alt=\"Waylon Walker\"></a> - Waylon Walker - <em>Original Author</em></p>\n<p><a href=\"https://github.com/mzjp2\"><img src=\"https://avatars3.githubusercontent.com/u/30357972?s=120&#x26;v=4\" alt=\"Zain Patel\"></a> - Zain Patel</p>\n<h2><img src=\"https://waylonwalker.com/find-kedro-release-8.png\" alt=\"License\"></h2>\n<p>This project is licensed under the MIT License - see the LICENSE.md file for details</p>","fields":{"slug":"/find-kedro-release/"},"frontmatter":{"tags":[],"title":"üì¢ Announcing find-kedro","description":"kedro is an amazing project that allows for super-fast prototyping of data pipelines, yet yielding production-ready pipelines. find-kedro enhances this experience by adding a pytest-like node discovery eliminating the need to bubble up pipelines through modules.","templateKey":"blog-post","status":"published","date":"2020-05-04T11:53:00.000Z","cover":null}},"next":{"id":"7b446eaa-096b-5b1d-b195-ddcc0e29144f","html":"<p>I was 20 commits into a hackoberfest PR when I suddenly realized they they all had my work email on them instead of my personal email üò±.  This is the story of how I corrected my email address on 19 individual commits after already submitting for a PR.</p>\n<ol>\n<li><a href=\"#change-the-email-for-this-repo\">Change the email for this repo</a></li>\n<li><a href=\"#prepare-for-rebasing\">Prepare for rebasing</a></li>\n<li><a href=\"#start-the-rebase\">start the rebase</a></li>\n<li><a href=\"#fix-first-wrong-commit\">üõ† Fix First wrong Commit</a></li>\n<li><a href=\"#fix-all-commits\">Fix all commits</a></li>\n<li><a href=\"#done\">Done</a></li>\n<li><a href=\"#recap\">ReCap</a></li>\n</ol>\n<h2>Change the email for this repo</h2>\n<p><em>stop the bleeding</em></p>\n<p>Before anything else set the email correctly!</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> kedro\n<span class=\"token function\">git</span> config user.name <span class=\"token string\">\"Waylon Walker\"</span>\n<span class=\"token function\">git</span> config user.email quadmx08@gmail.com</code></pre></div>\n<h2>Prepare for rebasing</h2>\n<p>First thing is to find how many commits back this mistake goes.  I opened up the git log, and saw mine went back 19 commits.  I rolled back 20 just to be sure.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">git</span> log\n<span class=\"token punctuation\">..</span>.\ncommit a355926b9d7ec4c05659adaa254beefbdb036332\nAuthor: WaylonWalker <span class=\"token operator\">&lt;</span>email@work.com<span class=\"token operator\">></span>\nDate:   Sat Oct <span class=\"token number\">17</span> <span class=\"token number\">10</span>:28:59 <span class=\"token number\">2020</span> -0500\n\n    give name of <span class=\"token keyword\">function</span> inside incorrect parameters error\n  \ncommit 1756f5d121bd06c459560b2e982e0d7b6879e9ca\nAuthor: Kiyohito Kunii <span class=\"token punctuation\">(</span>Kiyo<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span><span class=\"token number\">8097799</span>+921kiyo@users.noreply.github.com<span class=\"token operator\">></span>\nDate:   Fri Oct <span class=\"token number\">2</span> <span class=\"token number\">15</span>:33:09 <span class=\"token number\">2020</span> +0100\n\n    Fix docs reference <span class=\"token keyword\">for</span> registering <span class=\"token variable\"><span class=\"token variable\">`</span>pipelines<span class=\"token variable\">`</span></span></code></pre></div>\n<h2>start the rebase</h2>\n<p>Now I start the rebase 20 commits back from HEAD.  THis will pop you into a text file with a list of commits, for this change simply replace all <code class=\"language-text\">pick</code> with <code class=\"language-text\">edit</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> rebase -i HEAD~20</code></pre></div>\n<p>Run git log to see where we ended up.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">git</span> log\ncommit 1756f5d121bd06c459560b2e982e0d7b6879e9ca\nAuthor: Kiyohito Kunii <span class=\"token punctuation\">(</span>Kiyo<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span><span class=\"token number\">8097799</span>+921kiyo@users.noreply.github.com<span class=\"token operator\">></span>\nDate:   Fri Oct <span class=\"token number\">2</span> <span class=\"token number\">15</span>:33:09 <span class=\"token number\">2020</span> +0100\n\n    Fix docs reference <span class=\"token keyword\">for</span> registering <span class=\"token variable\"><span class=\"token variable\">`</span>pipelines<span class=\"token variable\">`</span></span></code></pre></div>\n<p>As expected we ended up on Kiyo's commit. So we can simply move forward without any edits.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">git</span> rebase --continue\nStopped at e162ca7<span class=\"token punctuation\">..</span>.  correct <span class=\"token keyword\">function</span> name <span class=\"token keyword\">in</span> tests\nYou can amend the commit now, with\n\n  <span class=\"token function\">git</span> commit --amend\n\nOnce you are satisfied with your changes, run\n\n  <span class=\"token function\">git</span> rebase --continue</code></pre></div>\n<h2>üõ† Fix First wrong Commit</h2>\n<p>Checking the log again I an now on my first commit with a mistake.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">git</span> log\ncommit 95c209a740d6d0340e19a8fc36298cbf874f8bf7 <span class=\"token punctuation\">(</span>HEAD<span class=\"token punctuation\">)</span>\nAuthor: WaylonWalker <span class=\"token operator\">&lt;</span>email@work.com<span class=\"token operator\">></span>\nDate:   Sat Oct <span class=\"token number\">3</span> <span class=\"token number\">11</span>:59:44 <span class=\"token number\">2020</span> -0500\n\n    correct <span class=\"token keyword\">function</span> name <span class=\"token keyword\">in</span> tests\n\ncommit cde2e8baa3c1c4a9f1da4135258381466b1da40a\nAuthor: Waylon Walker <span class=\"token operator\">&lt;</span>quadmx08@gmail.com<span class=\"token operator\">></span>\nDate:   Sat Oct <span class=\"token number\">17</span> <span class=\"token number\">10</span>:30:07 <span class=\"token number\">2020</span> -0500\n\n    update tests\n\ncommit a355926b9d7ec4c05659adaa254beefbdb036332\nAuthor: Waylon Walker <span class=\"token operator\">&lt;</span>quadmx08@gmail.com<span class=\"token operator\">></span>\nDate:   Sat Oct <span class=\"token number\">17</span> <span class=\"token number\">10</span>:28:59 <span class=\"token number\">2020</span> -0500\n\n    give name of <span class=\"token keyword\">function</span> inside incorrect parameters error\n\ncommit 1756f5d121bd06c459560b2e982e0d7b6879e9ca\nAuthor: Kiyohito Kunii <span class=\"token punctuation\">(</span>Kiyo<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span><span class=\"token number\">8097799</span>+921kiyo@users.noreply.github.com<span class=\"token operator\">></span>\nDate:   Fri Oct <span class=\"token number\">2</span> <span class=\"token number\">15</span>:33:09 <span class=\"token number\">2020</span> +0100\n\n    Fix docs reference <span class=\"token keyword\">for</span> registering <span class=\"token variable\"><span class=\"token variable\">`</span>pipelines<span class=\"token variable\">`</span></span></code></pre></div>\n<p>Running the following command will reset the author on the current commit.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> commit --amend --reset-author</code></pre></div>\n<p>Double check with a quick <code class=\"language-text\">git log</code> that the author was fixed.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">commit ccaaa56059ee4554731fa83297ca9e8e387a7592 <span class=\"token punctuation\">(</span>HEAD<span class=\"token punctuation\">)</span>\nAuthor: Waylon Walker <span class=\"token operator\">&lt;</span>quadmx08@gmail.com<span class=\"token operator\">></span>\nDate:   Sat Oct <span class=\"token number\">17</span> <span class=\"token number\">10</span>:35:40 <span class=\"token number\">2020</span> -0500\n\n    correct <span class=\"token keyword\">function</span> name <span class=\"token keyword\">in</span> tests\n\ncommit cde2e8baa3c1c4a9f1da4135258381466b1da40a\nAuthor: Waylon Walker <span class=\"token operator\">&lt;</span>quadmx08@gmail.com<span class=\"token operator\">></span>\nDate:   Sat Oct <span class=\"token number\">17</span> <span class=\"token number\">10</span>:30:07 <span class=\"token number\">2020</span> -0500\n\n    update tests\n\ncommit a355926b9d7ec4c05659adaa254beefbdb036332\nAuthor: Waylon Walker <span class=\"token operator\">&lt;</span>quadmx08@gmail.com<span class=\"token operator\">></span>\nDate:   Sat Oct <span class=\"token number\">17</span> <span class=\"token number\">10</span>:28:59 <span class=\"token number\">2020</span> -0500\n\n    give name of <span class=\"token keyword\">function</span> inside incorrect parameters error\n\ncommit 1756f5d121bd06c459560b2e982e0d7b6879e9ca\nAuthor: Kiyohito Kunii <span class=\"token punctuation\">(</span>Kiyo<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span><span class=\"token number\">8097799</span>+921kiyo@users.noreply.github.com<span class=\"token operator\">></span>\nDate:   Fri Oct <span class=\"token number\">2</span> <span class=\"token number\">15</span>:33:09 <span class=\"token number\">2020</span> +0100\n\n    Fix docs reference <span class=\"token keyword\">for</span> registering <span class=\"token variable\"><span class=\"token variable\">`</span>pipelines<span class=\"token variable\">`</span></span></code></pre></div>\n<h2>Fix all commits</h2>\n<p>Now to do this for 18 other commits.  I found that chaining the three commands into a bash one-liner was quite helpful.  I turned off pre-commit hooks with <code class=\"language-text\">--no-verify</code>.  I also turned off the <code class=\"language-text\">log</code> pager by adding <code class=\"language-text\">--no-pager</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> rebase --continue <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">\\</span>\n<span class=\"token function\">git</span> commit --amend --reset-author --no-edit --no-verify <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">\\</span>\n<span class=\"token function\">git</span> --no-pager log -n <span class=\"token number\">3</span></code></pre></div>\n<h2>Done</h2>\n<p>This was quick and easy for 19 commits.  I have tried to loop through changes like this in the past, and it does get a bit hairy.  I find its easier to just setup a one-liner and crank through them one by one.</p>\n<h2>A note on changing history...</h2>\n<p>Since this was done in a rebase it has changed the history of the repo.  This is ok to do only when you are the only person or are in close communication with everyone using the repo.  One thing I have ran into is that if you do this after you submit a PR, but before its completed it duplicates your commits in a merge.  For this particular change I simply closed the first PR and opened a second.  If someone has a better suggestion, I would be glad to know a better way.</p>\n<h2>ReCap</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> kedro\n<span class=\"token function\">git</span> config user.name <span class=\"token string\">\"Waylon Walker\"</span>\n<span class=\"token function\">git</span> config user.email quadmx08@gmail.com\n<span class=\"token function\">git</span> log\n<span class=\"token function\">git</span> rebase -i HEAD~20\n<span class=\"token function\">git</span> log\n<span class=\"token function\">git</span> rebase --continue\n<span class=\"token function\">git</span> log\n<span class=\"token function\">git</span> rebase --continue <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">git</span> commit --amend --reset-author --no-edit --no-verify <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">git</span> --no-pager log -n <span class=\"token number\">3</span></code></pre></div>","fields":{"slug":"/fix-git-commit-author/"},"frontmatter":{"tags":[],"title":"Fix git commit author","description":"I was 20 commits into a hackoberfest PR when I suddenly realized they they all had my work email on them instead of my personal email üò±.","templateKey":"blog-post","status":"published","date":"2020-10-17T05:00:00.000Z","cover":{"med_img":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABi0lEQVQY013Q32oTQRQG8DyBpiE12U226c5s/u3OnDlnE5PZTdYtaSNG4oUQCq2hlZLeVHqjN7nQK8UiFcUbQRC86wsUfCFfxNkthVI4DMPAb76Zr+B41Gii3aItj5wWmtU2JxwrTNgM2x0NsKMgRUgQRxAmPRWpMCbSSMNC3SMzFqc6x5qHdU622bigBhPm60o96ARj4wESUCNJY1QRUKxIKxoUTI6VYazejsElx3/yYnFy+m55dO4GWgSp8RISqUZCxVJFAoeAObZzYN1OhYHjhfvh/vuLy+/ffg3Cqd3steXoBkuDMZKoc8zxUTMsm9cyrLLslo1tP5XP/h1f/zn4+nv26Wp+eTFd/5h90LTnQwx3cYmhdPwBE5ucLKYshmVXhv7OKnr9Rq+OhsuXvcXb9OwwfiVgfD/Z7eLfLx8/H58/2BI2V9XMK+NNftENitv+w0a3xGRLxKYzATk2hd9gRPVzvXwezTecIKuN5Z6rmuk8a55q+Y/c9mOCVIeTtP806e+OexPe6f8HuNxg+JTPJj0AAAAASUVORK5CYII=","width":500,"height":210,"src":"/static/2e949c63dc0e41fc8348a2a7feba4fe4/46604/fix-git-commit-author-xmas2020.png","srcSet":"/static/2e949c63dc0e41fc8348a2a7feba4fe4/46604/fix-git-commit-author-xmas2020.png 1x,\n/static/2e949c63dc0e41fc8348a2a7feba4fe4/d8815/fix-git-commit-author-xmas2020.png 1.5x,\n/static/2e949c63dc0e41fc8348a2a7feba4fe4/31987/fix-git-commit-author-xmas2020.png 2x"}},"childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsTAAALEwEAmpwYAAABo0lEQVQoz3WRy0ojQRSG8wLeEO2kk3Qy3ZVO0t116lS1Jqm+2EYNqKCC4k4xio7gIuOIDMxEhmEYGHDnZaXgdnAzi3mEeQifxzKtiAvhW/yL+uo/h5MxKqjbvEi4YWORiDzBgoUlwjQLDJNXHYkwS1mCNOYYUhH7EDAhESXjzYx6nSNct1CFvIU64VqZ2lROzyxNGO5Ewa17sQcJQAwspBghC4BLwNaTnLNQkR2QZiXrdX/n6Hiv+3l1Y7dABIO2BzMUYsoijwWUSQ9bgC/yKyaOm16LzG2tHdzc35/1fxct33Sl7clUpgOZpnK2IrSKeO43mZp/uFz/s3z+cPC3v/7l38rFeefr2fzJz87pFLZdCN/I+WyFFKoa4cpUaCaUiL8vu9ed77+S029J71N0eLX4o5ccujSEl2ZI5dveyeX2x5ESzQ3klNGSo5lsuOyMlp0ho6rbokpDDyLV7EJL4bAGYCPz/65/vHk0lnfSsVPU5tpgBRV0U12B19zAx3ZTzEX+QuTPz053OAsy0RTahE1+eK19D6vWoBAJjAGCmtNUPz4CYAttCheu+OUAAAAASUVORK5CYII=","width":200,"height":85,"src":"/static/2e949c63dc0e41fc8348a2a7feba4fe4/71e30/fix-git-commit-author-xmas2020.png","srcSet":"/static/2e949c63dc0e41fc8348a2a7feba4fe4/71e30/fix-git-commit-author-xmas2020.png 1x,\n/static/2e949c63dc0e41fc8348a2a7feba4fe4/24123/fix-git-commit-author-xmas2020.png 1.5x,\n/static/2e949c63dc0e41fc8348a2a7feba4fe4/492a0/fix-git-commit-author-xmas2020.png 2x"}}}}},"similarPosts":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]}},"staticQueryHashes":["2992646504"]}