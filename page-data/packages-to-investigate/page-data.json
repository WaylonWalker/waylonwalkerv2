{"componentChunkName":"component---src-templates-blog-post-js","path":"/packages-to-investigate/","result":{"data":{"markdownRemark":{"id":"85d9b6f5-0ea1-57bb-99b4-318922a546db","html":"<ul>\n<li>jmespath</li>\n<li>Tabnine</li>\n</ul>\n<h1>Bulwark</h1>\n<p>|-|-|\n|github: |<a href=\"https://github.com/zaxr/bulwark\">https://github.com/zaxr/bulwark</a>|</p>\n<p>I definitely want to try this out with kedro.</p>\n<p>Bulwark is a package for convenient property-based testing of pandas dataframes, supported for Python 3.5+.</p>\n<h2>Example</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">    import bulwark.decorators as dc\n\n    @dc.IsShape((-1, 10))\n    @dc.IsMonotonic(strict=True)\n    @dc.HasNoNans()\n    def compute(df):\n        # complex operations to determine result\n        ...\n    return result_df</code></pre></div>","fields":{"slug":"/packages-to-investigate/"},"frontmatter":{"date":"2019-10-14T05:00:00.000Z","title":"Packages to Investigate","description":"jmespath Tabnine Bulwark |-|-| |github: |https://github.com/zaxr/bulwark| I definitely want to try this out with kedro","status":"published","cover":{"absolutePath":"/home/runner/work/waylonwalkerv2/waylonwalkerv2/static/packages-to-investigate-xmas2020.png","xsm_img":{"fixed":{"src":"/static/dab381783269abb847c190c282545628/ef958/packages-to-investigate-xmas2020.png","srcWebp":"/static/dab381783269abb847c190c282545628/f6b6d/packages-to-investigate-xmas2020.webp"}},"sm_img":{"fixed":{"src":"/static/dab381783269abb847c190c282545628/630fb/packages-to-investigate-xmas2020.png","srcWebp":"/static/dab381783269abb847c190c282545628/403a4/packages-to-investigate-xmas2020.webp"}},"med_img":{"fixed":{"src":"/static/dab381783269abb847c190c282545628/46604/packages-to-investigate-xmas2020.png","srcWebp":"/static/dab381783269abb847c190c282545628/e9589/packages-to-investigate-xmas2020.webp"}},"full":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABpElEQVQY002RS2vbQBSFvcyudhPi6BFblixpZGnm3rFk62ErUozANE3SFIprWmghXXRRTBsSSJy4LiTBxFl11X/S/9exvSkcPg7DnLlnZkr7TV43UbZ4rcn3LRSUxYoBsglqkxMnBsiBZchSxB5rpz7E0E44j5CHJbFDSDJWVEwUlA1UDZCEdNBMn7h9xnLGUoAe5X2EmPEEeAS8WxJzpCbf06Gqg7L2G1Z11rBD0spqVuCxnEJG4QAwZdijGHsYMtyEG6C3Qs3pvlSdXY2+kOyKTITZUV3L7Vfr1DBD4iROK7bswHbEWRHFaBUWPct1GhZnP++X1/PF9Ndicnk3uZqxqPh2cTv69HU6X9xMH7//mM3nT3ezx+Xz72506LIuE3fe1jlVW4mFeHCUDd/Gg5Oz8fng6F3DDZPBqRvkveLNq+MPw+Fo9P58NP5yfDr2O5kH67BG8O/yYfF5siVZFYVUFKcsk/K6tvA7Na8s29UatZ3YJqFpBxbxPRCvFa9qM4A/1x9fJyfbdaqYq3/aSDLwf2qk08Y88YvDzjDtFH1/YJDgHzL8Y9iLa1bAAAAAAElFTkSuQmCC","width":1000,"height":420,"src":"/static/dab381783269abb847c190c282545628/a8734/packages-to-investigate-xmas2020.png","srcSet":"/static/dab381783269abb847c190c282545628/a8734/packages-to-investigate-xmas2020.png 1x"},"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAABpElEQVQY002RS2vbQBSFvcyudhPi6BFblixpZGnm3rFk62ErUozANE3SFIprWmghXXRRTBsSSJy4LiTBxFl11X/S/9exvSkcPg7DnLlnZkr7TV43UbZ4rcn3LRSUxYoBsglqkxMnBsiBZchSxB5rpz7E0E44j5CHJbFDSDJWVEwUlA1UDZCEdNBMn7h9xnLGUoAe5X2EmPEEeAS8WxJzpCbf06Gqg7L2G1Z11rBD0spqVuCxnEJG4QAwZdijGHsYMtyEG6C3Qs3pvlSdXY2+kOyKTITZUV3L7Vfr1DBD4iROK7bswHbEWRHFaBUWPct1GhZnP++X1/PF9Ndicnk3uZqxqPh2cTv69HU6X9xMH7//mM3nT3ezx+Xz72506LIuE3fe1jlVW4mFeHCUDd/Gg5Oz8fng6F3DDZPBqRvkveLNq+MPw+Fo9P58NP5yfDr2O5kH67BG8O/yYfF5siVZFYVUFKcsk/K6tvA7Na8s29UatZ3YJqFpBxbxPRCvFa9qM4A/1x9fJyfbdaqYq3/aSDLwf2qk08Y88YvDzjDtFH1/YJDgHzL8Y9iLa1bAAAAAAElFTkSuQmCC","aspectRatio":2.380952380952381,"src":"/static/dab381783269abb847c190c282545628/a8734/packages-to-investigate-xmas2020.png","srcSet":"/static/dab381783269abb847c190c282545628/2d6f8/packages-to-investigate-xmas2020.png 250w,\n/static/dab381783269abb847c190c282545628/03ac3/packages-to-investigate-xmas2020.png 500w,\n/static/dab381783269abb847c190c282545628/a8734/packages-to-investigate-xmas2020.png 1000w","sizes":"(max-width: 1000px) 100vw, 1000px"}}}}}},"pageContext":{"id":"85d9b6f5-0ea1-57bb-99b4-318922a546db","prev":{"id":"885840a6-4629-5023-ae91-a4a3758caf58","html":"<p>This morning I logged into my machine and was nearly out of space</p>\n<ul>\n<li>64GB miniconda3!</li>\n<li>5GB conda cache</li>\n<li>4GM pip cache</li>\n<li>34GB docker</li>\n</ul>\n<h2>Find it</h2>\n<p><a href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--0LE2KZJW--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/je7pxcagfs7m23p98kck.jpg\"><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--0LE2KZJW--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/je7pxcagfs7m23p98kck.jpg\" alt=\"Looking for big files when the weeds are too tall\"></a></p>\n<blockquote>\n<p>Photo by <a href=\"https://unsplash.com/@simonmigaj?utm_source=unsplash&#x26;utm_medium=referral&#x26;utm_content=creditCopyText\">Simon Migaj</a> on <a href=\"https://unsplash.com/s/photos/find?utm_source=unsplash&#x26;utm_medium=referral&#x26;utm_content=creditCopyText\">Unsplash</a></p>\n</blockquote>\n<p>These are the commands that I often use to reclaim space.  Its so easy to fill up small vm's in the cloud, or in my case today let your dev machine go way too long without a good cleanup.</p>\n<h3>Show Remaining Space on Drives</h3>\n<p>This shows us where to start and gives a baseline of how much space we have reclaimed.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">df</span> -h</code></pre></div>\n<h3>show largest files in current directory</h3>\n<p>Next keep drilling into directories that are big and running this command to see whats big inside of it.  When you find somethign that you are willing to part with <code class=\"language-text\">rm -rf &lt;directory&gt;</code> it and check <code class=\"language-text\">df -h</code> to see if you have enough reclaimed yet.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">du</span> <span class=\"token builtin class-name\">.</span> -h --max-depth<span class=\"token operator\">=</span><span class=\"token number\">1</span></code></pre></div>\n<p>Honestly I rarely bother unless the directory is in the GB's of space.  A super simple filter for that is to just grep for G.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">du</span> <span class=\"token builtin class-name\">.</span> -h --max-depth<span class=\"token operator\">=</span><span class=\"token number\">1</span> <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> G</code></pre></div>\n<h2>conda</h2>\n<h3>How Many?</h3>\n<p>As a first baseline lets see how many enviroments we are starting with. I started with 71. Yeah I have had this machine for 2 years, and dont regularly remove them.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">conda info --envs <span class=\"token operator\">|</span> <span class=\"token function\">tail</span> -n +2 <span class=\"token operator\">|</span> <span class=\"token function\">wc</span> -l</code></pre></div>\n<p>bash</p>\n<h3>Lets batch it out!</h3>\n<p>We are devs here surely we can automate this issue! The following four lines will generate a list of existing conda environments, edit them with vim, remove the remaining ones, then remove the text file we created to remove from.</p>\n<p>Make sure that you only keep names of environments that you want to <strong>remove</strong> in <code class=\"language-text\">conda_envs_to_remove.txt</code> and delete the environment names you want to keep.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">conda info --envs <span class=\"token operator\">|</span> <span class=\"token function\">tail</span> -n +2 <span class=\"token operator\">|</span> <span class=\"token function\">cut</span> -d <span class=\"token string\">' '</span> -f1 <span class=\"token operator\">></span> conda_envs_to_remove.txt\n<span class=\"token function\">vim</span> conda_envs_to_remove.txt\n<span class=\"token function\">cat</span> ~/.conda_envs_remove <span class=\"token operator\">|</span> <span class=\"token function\">tr</span> <span class=\"token string\">'<span class=\"token entity\" title=\"\\n\">\\n</span>'</span> <span class=\"token string\">'<span class=\"token entity\" title=\"\\0\">\\0</span>'</span> <span class=\"token operator\">|</span> <span class=\"token function\">xargs</span> -l -0 conda remove --all -y -n\n<span class=\"token function\">rm</span> conda_envs_to_remove.txt</code></pre></div>\n<h3>üìù Side note</h3>\n<p>When I am creating one of these complicated bash pipelines including xargs I generally print out the command first and make sure that it does what I want. The following command will test the above script before doing dangerous things!</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">cat</span> ~/.conda_envs_remove <span class=\"token operator\">|</span> <span class=\"token function\">tr</span> <span class=\"token string\">'<span class=\"token entity\" title=\"\\n\">\\n</span>'</span> <span class=\"token string\">'<span class=\"token entity\" title=\"\\0\">\\0</span>'</span> <span class=\"token operator\">|</span> <span class=\"token function\">xargs</span> -l -0 <span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"conda remove --all -y -n \"</span></code></pre></div>\n<h2>Cache</h2>\n<p>If your feeling really strained for space, you can <code class=\"language-text\">rm -rf ~/.cache</code>. Personally I like the improved speed of installing everything... obviously I install a lot of new environments.</p>\n<h2>Docker</h2>\n<p><a href=\"https://res.cloudinary.com/practicaldev/image/fetch/s--W4NWBxYC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/olcef3lh31dtrwa51u7g.jpg\"><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--W4NWBxYC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/olcef3lh31dtrwa51u7g.jpg\" alt=\"Alt Text\"></a></p>\n<blockquote>\n<p>Photo by <a href=\"https://unsplash.com/@henry_be?utm_source=unsplash&#x26;utm_medium=referral&#x26;utm_content=creditCopyText\">Henry Be</a> on <a href=\"https://unsplash.com/s/photos/dark-fire?utm_source=unsplash&#x26;utm_medium=referral&#x26;utm_content=creditCopyText\">Unsplash</a></p>\n</blockquote>\n<p>For more information read this article, <a href=\"https://docs.docker.com/config/pruning/\" title=\"https://docs.docker.com/config/pruning/\">https://docs.docker.com/config/pruning/</a>. I have all of the images that I want pushed remotely so I just dumped everything with the following command.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">docker system prune\ndocker system prune --volumes</code></pre></div>\n<p>Running these two sets of commands cleared up about <strong>70GB</strong> of space for me with very little effort on my behalf. I hope others find the first command helpful to batch remove many conda environments at once.</p>","fields":{"slug":"/out-of-space/"},"frontmatter":{"tags":[],"title":"Out of Space","description":"Out of Space! How to remove 65 conda environments in one command.","templateKey":"blog-post","status":"published","date":"2020-02-01T06:00:00.000Z","cover":{"med_img":{"fixed":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMFAf/EABYBAQEBAAAAAAAAAAAAAAAAAAMAAf/aAAwDAQACEAMQAAABltY1jnGmX//EABoQAAIDAQEAAAAAAAAAAAAAAAACAQMhEhP/2gAIAQEAAQUCiuTyzkRizBn3/8QAFREBAQAAAAAAAAAAAAAAAAAAACH/2gAIAQMBAT8BV//EABYRAQEBAAAAAAAAAAAAAAAAAAABEf/aAAgBAgEBPwFsf//EABYQAQEBAAAAAAAAAAAAAAAAAAEQIP/aAAgBAQAGPwLAz//EABoQAAMBAAMAAAAAAAAAAAAAAAABESExQVH/2gAIAQEAAT8hxd3R8g9k5g6RF9hR2kf/2gAMAwEAAgADAAAAEKA//8QAFhEBAQEAAAAAAAAAAAAAAAAAERAh/9oACAEDAQE/EF2P/8QAFhEBAQEAAAAAAAAAAAAAAAAAARAR/9oACAECAQE/ENCH/8QAGhABAQEBAQEBAAAAAAAAAAAAAREAITFRcf/aAAgBAQABPxAN2DwNn7p+FT7u0cRj3uNJFRnkA7//2Q==","width":500,"height":341,"src":"/static/6d1d9c7c81cc5b8eb05340963497cfe5/0f3a1/photo-1464802686167-b939a6910659.jpg","srcSet":"/static/6d1d9c7c81cc5b8eb05340963497cfe5/0f3a1/photo-1464802686167-b939a6910659.jpg 1x,\n/static/6d1d9c7c81cc5b8eb05340963497cfe5/f9913/photo-1464802686167-b939a6910659.jpg 1.5x,\n/static/6d1d9c7c81cc5b8eb05340963497cfe5/a7715/photo-1464802686167-b939a6910659.jpg 2x"}},"childImageSharp":{"fixed":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABAAD/8QAFgEBAQEAAAAAAAAAAAAAAAAAAwEC/9oADAMBAAIQAxAAAAEmw0qRI9Nf/8QAGRABAAMBAQAAAAAAAAAAAAAAAQACEQMy/9oACAEBAAEFAqYljC2DSdPDP//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/AUf/xAAWEQEBAQAAAAAAAAAAAAAAAAAAERL/2gAIAQIBAT8BrT//xAAXEAEAAwAAAAAAAAAAAAAAAAABEBEg/9oACAEBAAY/Ai8Ef//EABkQAAMBAQEAAAAAAAAAAAAAAAABESExEP/aAAgBAQABPyFUERErMZZRyvJ0f//aAAwDAQACAAMAAAAQDy//xAAWEQEBAQAAAAAAAAAAAAAAAAABADH/2gAIAQMBAT8QHSJ//8QAFhEBAQEAAAAAAAAAAAAAAAAAABEB/9oACAECAQE/ENlT/8QAHBAAAgICAwAAAAAAAAAAAAAAAREAECFRcYGh/9oACAEBAAE/ENdg7iojsFYXMIUINLxmn//Z","width":200,"height":85,"src":"/static/6d1d9c7c81cc5b8eb05340963497cfe5/a6613/photo-1464802686167-b939a6910659.jpg","srcSet":"/static/6d1d9c7c81cc5b8eb05340963497cfe5/a6613/photo-1464802686167-b939a6910659.jpg 1x,\n/static/6d1d9c7c81cc5b8eb05340963497cfe5/b97e6/photo-1464802686167-b939a6910659.jpg 1.5x,\n/static/6d1d9c7c81cc5b8eb05340963497cfe5/eeb4b/photo-1464802686167-b939a6910659.jpg 2x"}}}}},"next":{"id":"802ef313-dd2e-5c58-9585-9468373fa9b1","html":"<h1>My favorite pandas pattern</h1>\n<p>I work with a lot of transactional timeseries data that includes categories.  I often want to create timeseries plots with each category as its own line.  This is the method that I use almost data to achieve this result.  Typically the data that am working with changes very slowly and trends happen over years not days or weeks.  Plotting daily/weekly data tends to be noisy and hides the trend.  I use this pattern because it works well with my data and is easy to explain to my stakeholders.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token operator\">%</span> matplotlib inline</code></pre></div>\n<h2>Lets Fake some data</h2>\n<p>Here I am trying to simulate a subset of a large transactional data set. This could be something like sales data, production data, hourly billing, anything that has a date, category, and value.  Since we generated this data we know that it is clean.  I am still going to assume that it contains some nulls, and an irregular date range.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">n <span class=\"token operator\">=</span> <span class=\"token number\">365</span><span class=\"token operator\">*</span><span class=\"token number\">5</span>\ncols <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'level_0'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'date'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'level_1'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'item'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token number\">0</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'qty'</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">}</span>\ndata <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                     columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'paper'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'pencils'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'note cards'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'markers'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                     index<span class=\"token operator\">=</span>pd<span class=\"token punctuation\">.</span>date_range<span class=\"token punctuation\">(</span><span class=\"token string\">'1/1/2017'</span><span class=\"token punctuation\">,</span> periods<span class=\"token operator\">=</span>n<span class=\"token punctuation\">,</span> freq<span class=\"token operator\">=</span><span class=\"token string\">'d'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                     <span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span>stack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span>to_frame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span>reset_index<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">.</span>rename<span class=\"token punctuation\">(</span>columns<span class=\"token operator\">=</span>cols<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndata<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>item</th>\n      <th>qty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-01-01</td>\n      <td>paper</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-01</td>\n      <td>pencils</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-01-01</td>\n      <td>note cards</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-01-01</td>\n      <td>markers</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-01-02</td>\n      <td>paper</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<h2>The pattern</h2>\n<p>Here I am going to take my groupby date and item, this will take care of duplicate entries with the same time stamp.  Select the value I want to sum on. unstack the items index into columns.  Resample the data by month.  I could easily use any of the <a href=\"https://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases\">available rules</a>. Fill any missing months with 0, since there wasnt a transaction during that month. Apply a rolling window to get the annual sum.  I find that this helps to ground values in values that my stakeholders are used to seeing on a regular basis and reduces the need for them to recalculate in their head.  Then I am going to drop the nulls created by the rolling window for the first 11 rows.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>data\n             <span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'item'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">[</span><span class=\"token string\">'qty'</span><span class=\"token punctuation\">]</span>\n             <span class=\"token punctuation\">.</span>unstack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span>resample<span class=\"token punctuation\">(</span><span class=\"token string\">'m'</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span>rolling<span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span>dropna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">)</span>\nplot_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item</th>\n      <th>markers</th>\n      <th>note cards</th>\n      <th>paper</th>\n      <th>pencils</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-12-31</th>\n      <td>1543.0</td>\n      <td>1739.0</td>\n      <td>1613.0</td>\n      <td>1657.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-31</th>\n      <td>1572.0</td>\n      <td>1744.0</td>\n      <td>1635.0</td>\n      <td>1635.0</td>\n    </tr>\n    <tr>\n      <th>2018-02-28</th>\n      <td>1563.0</td>\n      <td>1717.0</td>\n      <td>1645.0</td>\n      <td>1645.0</td>\n    </tr>\n    <tr>\n      <th>2018-03-31</th>\n      <td>1596.0</td>\n      <td>1703.0</td>\n      <td>1629.0</td>\n      <td>1600.0</td>\n    </tr>\n    <tr>\n      <th>2018-04-30</th>\n      <td>1557.0</td>\n      <td>1693.0</td>\n      <td>1648.0</td>\n      <td>1581.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>title<span class=\"token operator\">=</span><span class=\"token string\">'Rolling annual sum of Categorical Random Data'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<h2>For the Visual Learners</h2>\n<h3>Groupby</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>data\n             <span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'item'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n             <span class=\"token punctuation\">)</span>\nplot_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>qty</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th>item</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">2017-01-01</th>\n      <th>markers</th>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>note cards</th>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>paper</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>pencils</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2017-01-02</th>\n      <th>markers</th>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<h3>Select Values</h3>\n<p>In this case I chose to do this to avoid working with a multiple levels in the columns that would be created in the unstack() step.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data <span class=\"token operator\">=</span> plot_data<span class=\"token punctuation\">[</span><span class=\"token string\">'qty'</span><span class=\"token punctuation\">]</span>\n\nplot_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">date        item\n2017-01-01  markers       9\n            note cards    5\n            paper         1\n            pencils       4\n2017-01-02  markers       4\nName: qty, dtype: int32</code></pre></div>\n<h3>unstack</h3>\n<p>transform the last column in the index ('item') into rows.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data <span class=\"token operator\">=</span> plot_data<span class=\"token punctuation\">.</span>unstack<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nplot_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item</th>\n      <th>markers</th>\n      <th>note cards</th>\n      <th>paper</th>\n      <th>pencils</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-01</th>\n      <td>9</td>\n      <td>5</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2017-01-02</th>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2017-01-03</th>\n      <td>9</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2017-01-04</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2017-01-05</th>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<h3>resample</h3>\n<p>This step is important for irregular data in order to get the data into regular intervals.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data <span class=\"token operator\">=</span> plot_data<span class=\"token punctuation\">.</span>resample<span class=\"token punctuation\">(</span><span class=\"token string\">'m'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nplot_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item</th>\n      <th>markers</th>\n      <th>note cards</th>\n      <th>paper</th>\n      <th>pencils</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-31</th>\n      <td>145</td>\n      <td>128</td>\n      <td>117</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>2017-02-28</th>\n      <td>136</td>\n      <td>140</td>\n      <td>133</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>2017-03-31</th>\n      <td>112</td>\n      <td>145</td>\n      <td>125</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>2017-04-30</th>\n      <td>143</td>\n      <td>148</td>\n      <td>112</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>2017-05-31</th>\n      <td>86</td>\n      <td>134</td>\n      <td>139</td>\n      <td>141</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<h3>rolling</h3>\n<p>I like to use rolling because it get the data into annual numbers, and reduces noise.  I have found that most of my datasets have patterns and trends that are greater than 1y.  This  is just due to the industry that I am in.  Play with the resample and rolling rules to fit the need of your own data.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data <span class=\"token operator\">=</span> plot_data<span class=\"token punctuation\">.</span>rolling<span class=\"token punctuation\">(</span><span class=\"token number\">12</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nplot_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item</th>\n      <th>markers</th>\n      <th>note cards</th>\n      <th>paper</th>\n      <th>pencils</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-02-28</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-03-31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-04-30</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-05-31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-06-30</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-07-31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-08-31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-09-30</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-10-31</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-11-30</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2017-12-31</th>\n      <td>1543.0</td>\n      <td>1739.0</td>\n      <td>1613.0</td>\n      <td>1657.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-31</th>\n      <td>1572.0</td>\n      <td>1744.0</td>\n      <td>1635.0</td>\n      <td>1635.0</td>\n    </tr>\n    <tr>\n      <th>2018-02-28</th>\n      <td>1563.0</td>\n      <td>1717.0</td>\n      <td>1645.0</td>\n      <td>1645.0</td>\n    </tr>\n    <tr>\n      <th>2018-03-31</th>\n      <td>1596.0</td>\n      <td>1703.0</td>\n      <td>1629.0</td>\n      <td>1600.0</td>\n    </tr>\n    <tr>\n      <th>2018-04-30</th>\n      <td>1557.0</td>\n      <td>1693.0</td>\n      <td>1648.0</td>\n      <td>1581.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-31</th>\n      <td>1624.0</td>\n      <td>1674.0</td>\n      <td>1632.0</td>\n      <td>1592.0</td>\n    </tr>\n    <tr>\n      <th>2018-06-30</th>\n      <td>1582.0</td>\n      <td>1645.0</td>\n      <td>1657.0</td>\n      <td>1593.0</td>\n    </tr>\n    <tr>\n      <th>2018-07-31</th>\n      <td>1662.0</td>\n      <td>1654.0</td>\n      <td>1680.0</td>\n      <td>1613.0</td>\n    </tr>\n    <tr>\n      <th>2018-08-31</th>\n      <td>1654.0</td>\n      <td>1617.0</td>\n      <td>1650.0</td>\n      <td>1616.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n<h3>dropna</h3>\n<p>get rid of the first 11 null rows</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">plot_data <span class=\"token operator\">=</span> plot_data<span class=\"token punctuation\">.</span>dropna<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nplot_data<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">.dataframe tbody tr th {\n    vertical-align: top;\n}\n\n.dataframe thead th {\n    text-align: right;\n}</code></pre></div>\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>item</th>\n      <th>markers</th>\n      <th>note cards</th>\n      <th>paper</th>\n      <th>pencils</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-12-31</th>\n      <td>1543.0</td>\n      <td>1739.0</td>\n      <td>1613.0</td>\n      <td>1657.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-31</th>\n      <td>1572.0</td>\n      <td>1744.0</td>\n      <td>1635.0</td>\n      <td>1635.0</td>\n    </tr>\n    <tr>\n      <th>2018-02-28</th>\n      <td>1563.0</td>\n      <td>1717.0</td>\n      <td>1645.0</td>\n      <td>1645.0</td>\n    </tr>\n    <tr>\n      <th>2018-03-31</th>\n      <td>1596.0</td>\n      <td>1703.0</td>\n      <td>1629.0</td>\n      <td>1600.0</td>\n    </tr>\n    <tr>\n      <th>2018-04-30</th>\n      <td>1557.0</td>\n      <td>1693.0</td>\n      <td>1648.0</td>\n      <td>1581.0</td>\n    </tr>\n    <tr>\n      <th>2018-05-31</th>\n      <td>1624.0</td>\n      <td>1674.0</td>\n      <td>1632.0</td>\n      <td>1592.0</td>\n    </tr>\n    <tr>\n      <th>2018-06-30</th>\n      <td>1582.0</td>\n      <td>1645.0</td>\n      <td>1657.0</td>\n      <td>1593.0</td>\n    </tr>\n    <tr>\n      <th>2018-07-31</th>\n      <td>1662.0</td>\n      <td>1654.0</td>\n      <td>1680.0</td>\n      <td>1613.0</td>\n    </tr>\n    <tr>\n      <th>2018-08-31</th>\n      <td>1654.0</td>\n      <td>1617.0</td>\n      <td>1650.0</td>\n      <td>1616.0</td>\n    </tr>\n    <tr>\n      <th>2018-09-30</th>\n      <td>1669.0</td>\n      <td>1648.0</td>\n      <td>1638.0</td>\n      <td>1634.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","fields":{"slug":"/pandas-pattern/"},"frontmatter":{"tags":null,"title":"My favorite pandas pattern","description":"none","templateKey":"blog-post","status":"Draft","date":"2018-03-01T00:00:00.000Z","cover":{"med_img":{"fixed":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAECAwT/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAASdbKRmNv//EABoQAAIDAQEAAAAAAAAAAAAAAAECAAMRIQT/2gAIAQEAAQUCXDOAYBDyqpiw9Dsj/wD/xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAIAQMBAT8BbH//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAgEBPwFH/8QAGxABAAEFAQAAAAAAAAAAAAAAAQACESEiMVH/2gAIAQEABj8Cx2DVN+xToS77ApbYn//EABoQAQACAwEAAAAAAAAAAAAAAAEAESExQVH/2gAIAQEAAT8hSt9NvJlQviEWVRHk5chEiDK4aikRVn//2gAMAwEAAgADAAAAEOvv/8QAFhEAAwAAAAAAAAAAAAAAAAAAEBFB/9oACAEDAQE/EKgf/8QAFREBAQAAAAAAAAAAAAAAAAAAABH/2gAIAQIBAT8Qin//xAAeEAEAAgICAwEAAAAAAAAAAAABABEhUTFhQYGhsf/aAAgBAQABPxCnjNspi78nUtAEJUCda9xrjQE0BXH7FVAogI39iPh50cVqNmKDnLe5/9k=","width":500,"height":281,"src":"/static/6cceab946fd2933f6a07c2fb97f12123/0f3a1/crown-royal-bag-quilt.jpg","srcSet":"/static/6cceab946fd2933f6a07c2fb97f12123/0f3a1/crown-royal-bag-quilt.jpg 1x,\n/static/6cceab946fd2933f6a07c2fb97f12123/f9913/crown-royal-bag-quilt.jpg 1.5x,\n/static/6cceab946fd2933f6a07c2fb97f12123/a7715/crown-royal-bag-quilt.jpg 2x"}},"childImageSharp":{"fixed":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAwAC/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAbZNNFPL/8QAGxAAAQQDAAAAAAAAAAAAAAAAAQACETEDITL/2gAIAQEAAQUCbBWgIAWO39Cv/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAAAECMRAhIv/aAAgBAQAGPwLVicjuxZ//xAAbEAEAAgMBAQAAAAAAAAAAAAABABExQbEhUf/aAAgBAQABPyFK3wy6nqhekIsqiPk7pymCf//aAAwDAQACAAMAAAAQyw//xAAWEQEBAQAAAAAAAAAAAAAAAAAAASH/2gAIAQMBAT8QZH//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAfEAEAAQMEAwAAAAAAAAAAAAABEQAhURAxQWGBobH/2gAIAQEAAT8Qh4vZIWmeTqpQBCRAnWPNNbaAmAI2+6kPTr//2Q==","width":200,"height":85,"src":"/static/6cceab946fd2933f6a07c2fb97f12123/a6613/crown-royal-bag-quilt.jpg","srcSet":"/static/6cceab946fd2933f6a07c2fb97f12123/a6613/crown-royal-bag-quilt.jpg 1x,\n/static/6cceab946fd2933f6a07c2fb97f12123/b97e6/crown-royal-bag-quilt.jpg 1.5x,\n/static/6cceab946fd2933f6a07c2fb97f12123/eeb4b/crown-royal-bag-quilt.jpg 2x"}}}}},"similarPosts":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]}},"staticQueryHashes":["2992646504"]}